{
	"comment": "Run Fitted Q Iteration with generated dataset. Save NN weights to weightpath. Buffer size should be large enough to contain transitions from datalog. Agent.Seed corresponds to run (seed) of offline data.",
	"agent-name": "fqi",
	"environment-name": "futile",
	"agent-settings": {
		"decreasing-epsilon": "None",
		"gamma": 1.0,
		"state-len": 4,
		"buffer-type": "random",
		"optimizer": "Adam",
		"fqi-adamBeta1": 0.9,
		"fqi-adamBeta2": 0.999,
		"fqi-adamEps": 1e-8,
		"sweep": {
			"alpha": [1e-3, 1e-4, 1e-5, 1e-6],
			"fqi-hidden": [
				[4, 4], [16, 16], [64, 64]
			],
			"fqi-batch":[64],
			"fqi-sync":[512],
			"buffer-size":[10000],
			"epsilon": [0],
			"seed": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]
		},
		"lock-weight": false,
		"enable-debug": false,
		"datalog": "data/hyperparam/acrobot/offline_data/esarsa/step10k/optimalfixed_eps0/param_0/",
		"weightpath": "weight/hyperparam/acrobot/fqi/step10k_env/fixed_eps0/",
		"offline-learn": true,
		"online-learn": false
	},
	"environment-settings": {
		"seed": 1,
		"name": "acrobot",
		"sweep": {
			"delays":[[0]]
		}
	},
	"experiment-settings": {
		"steps": 256000,
		"data-path": "data/hyperparam/acrobot/offline_learning/fqi/fqi-adam/alpha_hidden_epsilon/step10k_env/data_eps0/lockat_baseline/",
		"should-log-traces": false,
		"should-log-episode-lengths": false,
		"should-log-learn-progress": true,
		"debug-interval": 1000
	}
}
