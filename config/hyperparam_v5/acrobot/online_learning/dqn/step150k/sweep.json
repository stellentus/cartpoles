{
	"agent-name": "dqn",
	"environment-name": "acrobot",
	"agent-settings": {
		"decreasing-epsilon": "None",
		"gamma": 1.0,
		"state-len": 2,
		"buffer-type": "random",
		"optimizer": "Adam",
		"dqn-adamBeta1": 0.9,
		"dqn-adamBeta2": 0.999,
		"dqn-adamEps": 1e-8,
		"sweep": {
			"alpha": [1e-2, 1e-3, 1e-4, 1e-5],
			"dqn-hidden": [
				[32, 32], [64, 64], [128, 128]
			],
			"dqn-sync":[512],
			"dqn-batch":[128, 256],
			"buffer-size":[2500],
			"epsilon": [0.1]
		},
		"lock-weight": false,
		"enable-debug": false,
		"seed": 1
	},
	"environment-settings": {
		"seed": 1
	},
	"experiment-settings": {
		"randomize_start_state_beforeLock": true,
		"randomize_start_state_afterLock": true,
		"steps": 0,
		"episodes": 10000000,
		"max-run-length-episodic": 150000,
		"data-path": "data/hyperparam_v5/acrobot/online_learning/dqn/step150k/sweep/",
		"should-log-totals": true,
		"should-log-returns": true,
		"debug-interval": 0
	}
}
